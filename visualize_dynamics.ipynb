{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt \n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from Kalman_VAE import KalmanVAE\n",
    "from datetime import datetime\n",
    "\n",
    "from dataloaders.bouncing_data import BouncingBallDataLoader\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join('/data2/users/lr4617/data/Bouncing_Ball/', 'train')\n",
    "test_dir = os.path.join('/data2/users/lr4617/data/Bouncing_Ball/', 'test')\n",
    "train_dl = BouncingBallDataLoader(train_dir, images=True)\n",
    "test_dl = BouncingBallDataLoader(test_dir, images=True)\n",
    "\n",
    "data = test_dl[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KalmanVAE(\n",
       "  (kalman_filter): Kalman_Filter(\n",
       "    (dyn_net): Dynamics_Network(\n",
       "      (lstm): LSTM(2, 128, num_layers=2, batch_first=True)\n",
       "      (linear): Linear(in_features=128, out_features=3, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (encoder): Gaussian_Encoder(\n",
       "    (conv_modules): ModuleList(\n",
       "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (to_mean): Linear(in_features=6400, out_features=2, bias=True)\n",
       "    (to_std): Linear(in_features=6400, out_features=2, bias=True)\n",
       "  )\n",
       "  (decoder): Gaussian_Decoder(\n",
       "    (to_conv): Linear(in_features=2, out_features=6400, bias=True)\n",
       "    (conv_tranpose_modules): ModuleList(\n",
       "      (0): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (2): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (to_mean): ConvTranspose2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_size = data.shape[2:]\n",
    "n_channels_in = data.shape[1]\n",
    "seq_len = data.shape[0]\n",
    "\n",
    "dim_a = 2\n",
    "dim_z = 4\n",
    "K = 3\n",
    "\n",
    "kvae = KalmanVAE(n_channels_in,\n",
    "                 image_size[0],\n",
    "                 dim_a, \n",
    "                 dim_z, \n",
    "                 K, \n",
    "                 T=seq_len, \n",
    "                 recon_scale=0.3).cuda()\n",
    "\n",
    "root_model_dir = '/data2/users/lr4617/KalmanVAE/results/Kalman_VAE/Bouncing_Ball/run_2023_11_04_14_24_56/'\n",
    "model_path = os.path.join(root_model_dir, '', 'kvae100.pt')\n",
    "kvae.load_state_dict(torch.load(model_path, map_location=torch.device('cuda:0')))\n",
    "kvae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_data = torch.Tensor(data).unsqueeze(0).to('cuda:0')\n",
    "\n",
    "a_mean, a_std = kvae.encoder(batched_data.view(-1, 1, 16, 16))\n",
    "a_sample = (a_mean + a_std*torch.normal(mean=torch.zeros_like(a_mean))).view(1, seq_len, dim_a)\n",
    "\n",
    "a_0 = kvae.kalman_filter.a_0.unsqueeze(0).unsqueeze(1).repeat(1, 1, 1)\n",
    "joint_code_obs = torch.cat([a_0, a_sample], dim=1)\n",
    "k_weights = kvae.kalman_filter.dyn_net(joint_code_obs[:, :-1, :])\n",
    "x_hat, _ = kvae.decoder(a_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_analysis_dir = os.path.join(root_model_dir, '', 'dyn_analysis')\n",
    "if not os.path.isdir(root_analysis_dir):\n",
    "    os.mkdir(root_analysis_dir)\n",
    "\n",
    "for step, (image, reconstruction, weight) in enumerate(zip(batched_data.squeeze(0).cpu(), x_hat.detach().cpu().numpy(), k_weights.squeeze(0))):\n",
    "    image = image > 0.5\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(10, 5))\n",
    "    fig.suptitle(f\"$t = {step}$\")\n",
    "\n",
    "    axes[0].imshow(image[0], vmin=0, vmax=1, cmap=\"Greys\", aspect='equal')\n",
    "    axes[0].set_adjustable('box') \n",
    "    axes[1].imshow(reconstruction[0], vmin=0, vmax=1, cmap=\"Greys\", aspect='equal')\n",
    "    axes[2].bar([\"0\", \"1\", \"2\"], weight.detach().cpu().numpy())\n",
    "    axes[2].set_ylim(0, 1)\n",
    "    axes[0].set_title(r\"image $\\mathbf{x}_t$\")\n",
    "    axes[1].set_title(r\"reconstruction $\\hat{\\mathbf{x}}_t$\")\n",
    "    axes[2].set_title(r\"weight $\\mathbf{k}_t$\")\n",
    "    pos_img = axes[0].get_position()\n",
    "    pos_bar = axes[2].get_position()\n",
    "    axes[2].set_position([pos_bar.x0, pos_img.y0, pos_bar.width, pos_img.height])\n",
    "    \n",
    "    fig.savefig(os.path.join(root_analysis_dir, 'weight-{}.png'.format(step)))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.3 Copyright (c) 2000-2020 the FFmpeg developers\n",
      "  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
      "  configuration: --prefix=/vol/bitbucket/lr4617/anaconda3/envs/py38_pytorch --cc=/opt/conda/conda-bld/ffmpeg_1597178665428/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-gnutls --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-pic --enable-pthreads --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libmp3lame\n",
      "  libavutil      56. 51.100 / 56. 51.100\n",
      "  libavcodec     58. 91.100 / 58. 91.100\n",
      "  libavformat    58. 45.100 / 58. 45.100\n",
      "  libavdevice    58. 10.100 / 58. 10.100\n",
      "  libavfilter     7. 85.100 /  7. 85.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  7.100 /  5.  7.100\n",
      "  libswresample   3.  7.100 /  3.  7.100\n",
      "Input #0, image2, from '/data2/users/lr4617/KalmanVAE/results/Kalman_VAE/Bouncing_Ball/run_2023_11_04_14_24_56/dyn_analysis/weight-%d.png':\n",
      "  Duration: 00:00:05.00, start: 0.000000, bitrate: N/A\n",
      "    Stream #0:0: Video: png, rgba(pc), 720x360 [SAR 2835:2835 DAR 2:1], 10 fps, 10 tbr, 10 tbn, 10 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libopenh264))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libopenh264 @ 0x5562d524ec40] \u001b[0m\u001b[0;33mSlice count will be set automatically\n",
      "\u001b[0m\u001b[1;36m[libopenh264 @ 0x5562d524ec40] \u001b[0m\u001b[0;33m[OpenH264] this = 0x0x5562d51dea90, Warning:SliceArgumentValidationFixedSliceMode(), unsupported setting with Resolution and uiSliceNum combination under RC on! So uiSliceNum is changed to 4!\n",
      "\u001b[0m\u001b[1;36m[libopenh264 @ 0x5562d524ec40] \u001b[0m\u001b[0;33m[OpenH264] this = 0x0x5562d51dea90, Warning:bEnableFrameSkip = 0,bitrate can't be controlled for RC_QUALITY_MODE,RC_BITRATE_MODE and RC_TIMESTAMP_MODE without enabling skip frame.\n",
      "\u001b[0m\u001b[1;36m[libopenh264 @ 0x5562d524ec40] \u001b[0m\u001b[0;33m[OpenH264] this = 0x0x5562d51dea90, Warning:Change QP Range from(0,51) to (12,42)\n",
      "\u001b[0mOutput #0, mp4, to '/data2/users/lr4617/KalmanVAE/results/Kalman_VAE/Bouncing_Ball/run_2023_11_04_14_24_56/dyn_analysis/weight.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.45.100\n",
      "    Stream #0:0: Video: h264 (libopenh264) (avc1 / 0x31637661), yuv420p, 720x360 [SAR 1:1 DAR 2:1], q=-1--1, 30 fps, 15360 tbn, 30 tbc\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.91.100 libopenh264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/2000000 buffer size: 0 vbv_delay: N/A\n",
      "frame=  150 fps=0.0 q=-0.0 Lsize=      46kB time=00:00:04.96 bitrate=  76.6kbits/s dup=100 drop=0 speed=22.5x    \n",
      "video:45kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 3.087865%\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -framerate 10 -i /data2/users/lr4617/KalmanVAE/results/Kalman_VAE/Bouncing_Ball/run_2023_11_04_14_24_56/dyn_analysis/weight-%d.png -c:v libopenh264 -r 30 -pix_fmt yuv420p /data2/users/lr4617/KalmanVAE/results/Kalman_VAE/Bouncing_Ball/run_2023_11_04_14_24_56/dyn_analysis/weight.mp4 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"/data2/users/lr4617/KalmanVAE/results/Kalman_VAE/Bouncing_Ball/run_2023_11_04_14_24_56/dyn_analysis/weight.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(\"/data2/users/lr4617/KalmanVAE/results/Kalman_VAE/Bouncing_Ball/run_2023_11_04_14_24_56/dyn_analysis/weight.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
